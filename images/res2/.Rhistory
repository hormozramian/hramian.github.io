)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 2, activation = 'relu',input_shape=c(n_features)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_rmsprop()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 20, batch_size = nrow(X_train),
validation_split = 0
)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 2, activation = 'relu',input_shape=c(n_features)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_rmsprop()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 1000, batch_size = nrow(X_train),
validation_split = 0
)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 4, activation = 'sigmoid',input_shape=c(n_features)) %>%
layer_dense(units = 2, activation = 'sigmoid',input_shape=c(n_features)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_rmsprop()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 1000, batch_size = nrow(X_train),
validation_split = 0
)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 4, activation = 'sigmoid',input_shape=c(n_features)) %>%
layer_dense(units = 2, activation = 'sigmoid',input_shape=c(n_features)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_rmsprop()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 200, batch_size = nrow(X_train),
validation_split = 0
)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 4, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 2, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 200, batch_size = nrow(X_train),
validation_split = 0
)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_test), y_test)
mean(X_train[,1])
mean(X_train[,2])
mean(X_train[,3])
sd(X_train[,3])
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 4, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 2, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 200, batch_size =128,
validation_split = 0
)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 4, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 2, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 500, batch_size =256,
validation_split = 0
)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 64, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 32, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 16, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 8, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 2000, batch_size =256,
validation_split = 0
)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 64, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 32, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 16, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 8, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 800, batch_size =256,
validation_split = 0.1
)
model %>% evaluate(data.matrix(X_test), y_test)
plot(history)
model %>% evaluate(x_test, y_test)
model %>% evaluate(data.matrix(X_test), y_test)
plot(history)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 64, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 32, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 16, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 8, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 300, batch_size =256,
validation_split = 0.1
)
model %>% evaluate(data.matrix(X_test), y_test)
plot(history)
model %>% evaluate(data.matrix(X_test), y_test)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 128, activation = 'sigmoid',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 64, activation = 'sigmoid',kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 32, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 16, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 8, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_adam()
)
early_stopping <- callback_early_stopping(monitor = 'val_loss', patience = 2)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 600, batch_size =256,
callbacks = c(early_stopping),
validation_split = 0.1
)
model %>% evaluate(data.matrix(X_test), y_test)
plot(history)
model %>% evaluate(data.matrix(X_test), y_test)
plot(history)
model %>% evaluate(data.matrix(X_validate), y_validate)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_validate), y_validate)
model %>% evaluate(data.matrix(X_train), y_train)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_validate), y_validate)
df = fread("~/Dropbox/File requests/deep-learning-mice/Andrew Alden - AndrewAlden-843322.csv")
head(df)
df = fread("~/Dropbox/File requests/deep-learning-mice/Andrew Alden - AndrewAlden-843322.csv")
library(data.table)
df = fread("~/Dropbox/File requests/deep-learning-mice/Andrew Alden - AndrewAlden-843322.csv")
head(df)
df$yhat - y_validate
mean((df$yhat - y_validate)^2)
submit_answers = function(yhat,team="Pick a nickname for yourself or team; should not contain spaces or special characters") {
team = gsub("[[:punct:]]", "", team)
team = gsub(" ", "", team, fixed = TRUE)
if(length(yhat) == 153 & class(yhat) == "numeric") {
id = round(abs(sum(yhat)*1000))
print(sprintf("Saving %s-%d.csv",team,id))
df = data.frame(yhat=yhat,team=team)
write.csv(df,sprintf("%s-%d.csv",team,id),row.names=F)
} else {
print("Something went wrong. You should supply a numeric vector yhat of length 153 containing your predictions.")
}
}
y_hat = model %>% evaluate(data.matrix(X_validate), y_validate)
y_hat
y_hat = model %>% predict(data.matrix(X_validate), y_validate)
y_hat =  predict(model,data.matrix(X_validate))
submit_answers(y_hat,"SethFlaxman")
y_hat
a = model %>% evaluate(data.matrix(X_validate))
a = model %>% predict(data.matrix(X_validate))
a
model %>% evaluate(data.matrix(X_validate), y_validate)
y_validate
y_test
y_train
X_validate[1:5,]
a = model %>% predict(data.matrix(X_validate))
y_hat
submit_answers(as.numeric(y_hat),"SethFlaxman")
library(data.table)
for(f in list.files("~/Dropbox/File requests/deep-learning-mice/")) {
df = fread(f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2))
}
library(data.table)
for(f in list.files("~/Dropbox/File requests/deep-learning-mice/")) {
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2))
}
library(data.table)
for(f in list.files("~/Dropbox/File requests/deep-learning-mice/")) {
df = fread(f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
f
setwd(""~/Dropbox/File requests/deep-learning-mice/"")
library(data.table)
setwd("~/Dropbox/File requests/deep-learning-mice/")
for(f in list.files(".")) {
df = fread(f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
library(data.table)
setwd("~/Dropbox/File requests/deep-learning-mice/")
for(f in list.files(".")) {
df = fread(f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
hist(v)
hist(y_hat)
range(y_validate)
load("data/mice-with-validate.rdata")
n_features = ncol(X_train)
#X_train <- array_reshape(data.matrix(X_train), c(nrow(X_train), n_features, 1))
#X_test <- array_reshape(data.matrix(X_test), c(nrow(X_test), n_features, 1))
#X_validate <- array_reshape(data.matrix(X_validate), c(nrow(X_validate), n_features, 1))
model <- keras_model_sequential() %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = c(n_features,1)) %>%
# layer_dropout(rate = 0.9,input_shape=c(n_features)) %>%
layer_dense(units = 128, activation = 'relu',input_shape=c(n_features), kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dense(units = 64, activation = 'sigmoid',kernel_regularizer = regularizer_l2(l = 0.001)) %>%
#layer_dense(units = 32, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
#layer_dense(units = 16, activation = 'sigmoid', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
layer_dense(units = 8, activation = 'relu', kernel_regularizer = regularizer_l2(l = 0.001)) %>%
# layer_dropout(rate = 0.5) %>%
#  layer_conv_1d(filters = 4, kernel_size = c(10), activation = 'relu',
#                input_shape = input_shape) %>%
# layer_flatten() %>%
#  layer_dense(units = 5, activation = 'relu') %>%
# layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
# Train model
model %>% compile(
loss = 'mean_squared_error',
optimizer = optimizer_rmsprop()
)
early_stopping <- callback_early_stopping(monitor = 'val_loss', patience = 2)
history <- model %>% fit(
data.matrix(X_train), y_train,
epochs = 1000, batch_size =512,
callbacks = c(early_stopping),
validation_split = 0.1
)
model %>% evaluate(data.matrix(X_train), y_train)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_validate), y_validate)
y_hat =  predict(model,data.matrix(X_validate))
a = model %>% predict(data.matrix(X_validate))
plot(history)
a = model %>% predict(data.matrix(X_validate))
model %>% evaluate(data.matrix(X_validate), y_validate)
model %>% evaluate(data.matrix(X_train), y_train)
model %>% evaluate(data.matrix(X_test), y_test)
model %>% evaluate(data.matrix(X_validate), y_validate)
y_hat = model %>% predict(data.matrix(X_validate))
plot(history)
library(data.table)
setwd("~/Dropbox/File requests/deep-learning-mice/")
for(f in list.files(".")) {
df = fread(f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
library(data.table)
setwd("~/Dropbox/File requests/deep-learning-mice/")
for(f in list.files(".")) {
df = fread(f)
plot(y_validate,df$yhat,main=f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
setwd("~/Dropbox/Seth/Imperial/Teaching/ML-QSRI/practicals")
load("data/mice.rdata")
range(y_train)
range(y_test)
range(y_validate)
load("data/mice-with-validate.rdata")
range(y_validate)
range(y_test)
range(y_train)
library(data.table)
setwd("~/Dropbox/File requests/deep-learning-mice/")
for(f in list.files(".")) {
df = fread(f)
plot(y_validate,df$yhat,main=f)
print(sprintf("%s %.03f",f,mean((df$yhat - y_validate)^2)))
}
setwd("~/Dropbox/Seth/Imperial/Teaching/ML-QSRI/BS8008-1819/published/ML/practicals")
---
title: 'Day 1: regression and classification'
author: "Seth Flaxman"
date: "2 July 2019"
output: html_document
---
```{r setup, include=FALSE}
